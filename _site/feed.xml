<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-13T14:51:08+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Hirosi Dev Blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">딥러닝 개론</title><link href="http://localhost:4000/2022/05/13/%EB%94%A5%EB%9F%AC%EB%8B%9D.html" rel="alternate" type="text/html" title="딥러닝 개론" /><published>2022-05-13T13:57:56+09:00</published><updated>2022-05-13T13:57:56+09:00</updated><id>http://localhost:4000/2022/05/13/%EB%94%A5%EB%9F%AC%EB%8B%9D</id><content type="html" xml:base="http://localhost:4000/2022/05/13/%EB%94%A5%EB%9F%AC%EB%8B%9D.html"><![CDATA[<h1 id="딥러닝-개론">딥러닝 개론</h1>
<h2 id="퍼셉트론">퍼셉트론</h2>
<h3 id="01-인공-신경망">01 인공 신경망</h3>
<p>데이터  -&gt; input layer -&gt; 1 hidden layer -&gt; … layer -&gt; output layer 
=&gt; 회귀분석, 분류, 패턴파악.</p>

<p>테이트의 특성 = feature</p>

<p>지도학슴(class)</p>

<p>비지도 학습 (clustering)</p>

<h3 id="02-퍼셉트론-perceptron">02 퍼셉트론 (Perceptron)</h3>
<p>네트워크를 이루는 하나하나의 요소를 퍼셉트론 이라 한다.</p>

<p><img src="/assets/2022-05-13-딥러닝/img.png" alt="img.png" /></p>
<blockquote>
  <p>활성화 함수 : 비선형함수이다.</p>
</blockquote>

<h4 id="활성화-함수-activation-function">활성화 함수 (Activation function)</h4>
<p><img src="/assets/2022-05-13-딥러닝/img_1.png" alt="img_1.png" /></p>

<p><img src="/assets/2022-05-13-딥러닝/img_2.png" alt="img_2.png" /></p>

<p><img src="/assets/2022-05-13-딥러닝/img_3.png" alt="img_3.png" /></p>

<h4 id="퍼셉트론-코드-예시">퍼셉트론 코드 예시</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">perceptron</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="c1"># bias
</span>    <span class="n">sum_</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">sum_</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">sum_</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
</code></pre></div></div>
<p><img src="/assets/2022-05-13-딥러닝/img_4.png" alt="img_4.png" /></p>

<h3 id="03-퍼셉트론-선형-분류기">03 퍼셉트론 선형 분류기</h3>
<h5 id="퍼셉트론-논리회로---and-gate">퍼셉트론 논리회로 - AND gate</h5>
<p><img src="/assets/2022-05-13-딥러닝/img_5.png" alt="img_5.png" /></p>
<blockquote>
  <p>AND gate:</p>

  <p>c = activation( 1 * A + 1 * B - 1.5)</p>
  <h5 id="퍼셉트론-논리회로---or-gate">퍼셉트론 논리회로 - OR gate</h5>
  <p><img src="/assets/2022-05-13-딥러닝/img_6.png" alt="img_6.png" />
OR gate:</p>

  <p>c = activation( 1 * A + 1 * B - 0.5)</p>
  <h5 id="퍼셉트론-논리회로---nor-gate">퍼셉트론 논리회로 - NOR gate</h5>
  <p><img src="/assets/2022-05-13-딥러닝/img_8.png" alt="img_8.png" />
NOR gate</p>

  <p>C = activation((-1)<em>A + (-1)</em>B + 0.5 )</p>
  <h5 id="퍼셉트론-논리회로---nand-gate">퍼셉트론 논리회로 - NAND gate</h5>
  <p><img src="/assets/2022-05-13-딥러닝/img_9.png" alt="img_9.png" />
NAND gate</p>

  <p>C = activation((-1)<em>A + (-1)</em>B + 1.5 )</p>
</blockquote>

<p>이외의 NOR, NAND 포함하여, Linar classifier</p>

<p><img src="/assets/2022-05-13-딥러닝/img_7.png" alt="img_7.png" /></p>

<h3 id="04-비-선형적인-문제">04 비 선형적인 문제</h3>
<h5 id="비-선형적-논리-게이트-xor-gate">비 선형적 논리 게이트, XOR gate</h5>

<p>–&gt; xor로 인하여 빙하기~</p>

<h3 id="05-다층-피셉트론">05 다층 피셉트론</h3>
<p><img alt="/assets/2022-05-13-딥러닝/img_10.png" src="/assets/2022-05-13-딥러닝/img_10.png" width="400" /></p>

<p>Hidden layer가 많아질 수록, complexity가 증가</p>

<p>이를 경우 deep learning이라고 함.</p>

<hr />

<h2 id="예제-문제">예제 문제</h2>
<h3 id="다층-퍼셉트론mlp-모델로-2d-데이터-분류하기">다층 퍼셉트론(MLP) 모델로 2D 데이터 분류하기</h3>
<p><code class="language-plaintext highlighter-rouge">data</code> 폴더에 위치한 <code class="language-plaintext highlighter-rouge">test.txt</code> 데이터와 <code class="language-plaintext highlighter-rouge">train.txt</code> 데이터를 활용하여 2-D 평면에 0과 1로 이루어진 점들의 각 좌표 정보 (x,y)(x, y)(x,y) 를 통해 모델을 학습시키겠습니다.</p>

<p><code class="language-plaintext highlighter-rouge">hidden_layer_sizes</code>를 조정해보면서 다층 퍼셉트론 분류 모델을 학습시켜 모델의 정확도가 81% 를 넘도록 해봅시다.</p>

<p>이전 실습에서 단층 퍼셉트론인 AND, OR, NAND Gate를 구현하고, 이들을 쌓아서 XOR Gate를 만들어 보았습니다. 즉, XOR Gate는 단층 퍼셉트론을 여러 개 쌓아서 만든 다층 퍼셉트론 (MLP: Multi Layer Perceptron)이라고 할 수 있습니다. 다층 퍼셉트론으로 만든 모델은 인공 신경망이라고도 합니다.</p>

<p>image</p>

<p>이번 실습에서는 사이킷런에서 제공하는 다층 퍼셉트론 모델인 <code class="language-plaintext highlighter-rouge">MLPClassifier</code>를 이용해서 2D 데이터를 분류해보겠습니다.
<img alt="/assets/2022-05-13-딥러닝/img_11.png" src="/assets/2022-05-13-딥러닝/img_11.png" width="600" /></p>

<hr />

<p>다층 퍼셉트론 모델을 사용하기 위한 사이킷런 함수/라이브러리</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">from sklearn.neural_network import MLPClassifier</code>: 사이킷런에 구현되어 있는 다층 퍼셉트론 모델을 불러옵니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">MLPClassifier(hidden_layer_sizes)</code>: MLPClassifier를 정의합니다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">hidden_layer_sizes</code>: 간단하게 hidden layer의 크기를 조절할 수 있는 인자입니다.</p>
  </li>
</ul>

<hr />

<p><code class="language-plaintext highlighter-rouge">MLPClassifier</code>는 역전파(backpropagation)라는 기법을 사용하여 모델을 학습합니다. 역전파는 2장에서 자세하게 배울 수 있으니 여기선 용어만 알아둡시다.</p>

<p>밑의 소스 코드는 첫 번째 히든층에 4개, 두 번째 히든층에 4개의 퍼셉트론을 가지게 설정한 것이고, 위 그림과 같은 모델을 나타냅니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</code></pre></div></div>
<h4 id="실습">실습</h4>
<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">MLPClassifier</code>를 정의하고 <code class="language-plaintext highlighter-rouge">hidden_layer_sizes</code>를 조정해 히든층의 레이어의 개수와 퍼셉트론의 개수를 바꿔본 후, 학습을 시킵니다.</p>
  </li>
  <li>
    <p>정확도를 출력하는 report_clf_stats함수를 완성합니다. hit는 맞춘 데이터의 개수, miss는 못 맞춘 데이터의 개수입니다. 정확도 점수 score는 (맞춘 데이터의 개수 / 전체 데이터 개수) x 100으로 정의하겠습니다. score를 코드로 작성해보세요.</p>
  </li>
  <li>
    <p>앞서 완성한 함수를 실행시키는 main 함수를 완성합니다. 코드 주석의 Step들을 참고하세요.</p>
  </li>
  <li>
    <p>일반적으로, 레이어 내의 퍼셉트론의 개수가 많아질수록 성능이 올라가는 것을 확인할 수 있습니다. 레이어의 개수와 퍼셉트론의 개수를 극단적으로 늘려보기도 하고, 줄여보면서 정확도를 81% 이상으로 늘려보세요.</p>
  </li>
</ol>

<h4 id="출력-예시">출력 예시</h4>
<p>아래 이미지는 학습 결과에 대한 출력 예시입니다. 그래프에서 나타나는 배경색은 모델이 예측한 결과, O/X 가 나타내는 색은 실제값 (ground truth) 입니다. 모델이 맞게 예측한 경우 O, 틀리게 예측한 경우 X 로 표시됩니다.
<img src="/assets/2022-05-13-딥러닝/img_12.png" alt="img_12.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">visual</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="kn">from</span> <span class="nn">elice_utils</span> <span class="kn">import</span> <span class="n">EliceUtils</span>
<span class="n">elice_utils</span> <span class="o">=</span> <span class="n">EliceUtils</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    
<span class="c1"># 데이터를 읽어오는 함수입니다.
</span><span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">fp</span><span class="p">.</span><span class="n">readline</span><span class="p">().</span><span class="n">split</span><span class="p">()</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">fp</span><span class="p">.</span><span class="n">readline</span><span class="p">().</span><span class="n">split</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
                <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
                <span class="n">Y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>    
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="s">'''
1. MLPClassifier를 정의하고 hidden_layer_sizes를
   조정해 hidden layer의 크기 및 레이어의 개수를
   바꿔본 후, 학습을 시킵니다. Done
'''</span>

<span class="k">def</span> <span class="nf">train_MLP_classifier</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>   
    <span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
    <span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">clf</span>

<span class="s">'''
2. 테스트 데이터에 대한 정확도를 출력하는 
   함수를 완성합니다. 설명을 보고 score의 코드를
   작성해보세요. Done
'''</span>

<span class="k">def</span> <span class="nf">report_clf_stats</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    
    <span class="n">hit</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">miss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">([</span><span class="n">x</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="p">:</span>
            <span class="n">hit</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">miss</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">score</span> <span class="o">=</span> <span class="n">hit</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"Accuracy: %.1lf%% (%d hit / %d miss)"</span> <span class="o">%</span> <span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">hit</span><span class="p">,</span> <span class="n">miss</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">score</span>

<span class="s">'''
3. main 함수를 완성합니다.

   Step01. 학습용 데이터인 X_train, Y_train과
           테스트용 데이터인 X_test, Y_test를 각각
           read_data에서 반환한 값으로 정의합니다. 
           
           우리가 사용할 train.txt 데이터셋과
           test.txt 데이터셋은 data 폴더에 위치합니다.
           
   Step02. 앞에서 학습시킨 다층 퍼셉트론 분류 
           모델을 'clf'로 정의합니다. 'clf'의 변수로는
           X_train과 Y_train으로 설정합니다.
           
   Step03. 앞에서 완성한 정확도 출력 함수를
           'score'로 정의합니다. 'score'의 변수로는
           X_test와 Y_test로 설정합니다.
'''</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>  
    <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s">'data/train.txt'</span><span class="p">)</span>    
    <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="s">'data/test.txt'</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">train_MLP_classifier</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">report_clf_stats</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
    <span class="n">visualize</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train.txt
['10 10\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 1 1 1 0 0 0 0\n', '0 0 1 1 1 1 1 0 0 0\n', '0 1 1 1 1 1 1 1 0 0\n', '0 1 1 1 1 1 1 1 0 0\n', '1 1 1 1 1 1 1 1 1 0\n', '1 1 1 1 1 1 1 1 1 0\n', '1 1 1 1 1 1 1 1 1 0']
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test.txt
['10 10\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 0 0 0 0 0 0 0\n', '0 0 0 0 0 1 1 1 0 0\n', '0 0 0 0 1 1 1 1 1 0\n', '0 0 0 1 1 1 1 1 1 0\n', '0 0 1 1 1 1 1 1 1 0\n', '0 1 1 1 1 1 1 1 1 1\n', '1 1 1 1 1 1 1 1 1 1\n', '1 1 1 1 1 1 1 1 1 1\n']
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[딥러닝 개론 퍼셉트론 01 인공 신경망 데이터 -&gt; input layer -&gt; 1 hidden layer -&gt; … layer -&gt; output layer =&gt; 회귀분석, 분류, 패턴파악.]]></summary></entry><entry><title type="html">테스트로 한번 만들어 본다</title><link href="http://localhost:4000/2022/05/13/new_post.html" rel="alternate" type="text/html" title="테스트로 한번 만들어 본다" /><published>2022-05-13T12:57:56+09:00</published><updated>2022-05-13T12:57:56+09:00</updated><id>http://localhost:4000/2022/05/13/new_post</id><content type="html" xml:base="http://localhost:4000/2022/05/13/new_post.html"><![CDATA[<h1 id="테스트로-한번-만들어-본다">테스트로 한번 만들어 본다</h1>
<p>그냥 만드는 거니 그냥 만들었으니 그냥 놀자
this is a apple</p>]]></content><author><name></name></author><summary type="html"><![CDATA[테스트로 한번 만들어 본다 그냥 만드는 거니 그냥 만들었으니 그냥 놀자 this is a apple]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2022/05/13/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2022-05-13T10:57:56+09:00</published><updated>2022-05-13T10:57:56+09:00</updated><id>http://localhost:4000/jekyll/update/2022/05/13/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2022/05/13/welcome-to-jekyll.html"><![CDATA[<h1 id="welcome-to-jekyll">“Welcome to Jekyll!”</h1>
<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code></p>

<p>Where <code class="language-plaintext highlighter-rouge">YEAR</code> is a four-digit number, <code class="language-plaintext highlighter-rouge">MONTH</code> and <code class="language-plaintext highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="language-plaintext highlighter-rouge">MARKUP</code> is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span></code></pre></figure>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[“Welcome to Jekyll!” You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry></feed>